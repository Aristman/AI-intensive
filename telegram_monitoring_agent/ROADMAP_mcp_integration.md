# ROADMAP: Интеграция Telegram MCP сервера (stdio/stdout) в telegram_monitoring_agent

Дата: 2025-09-05
Модуль: `telegram_monitoring_agent/`
Цель: подключить `mcp_servers/telegram_mcp_server/` как внешний процесс (Node.js) c транспортом stdio/stdout и использовать его инструменты Telegram в пайплайнах агента.

## Цели и критерии приёмки
- [ ] MCP сервер запускается агентом как дочерний процесс (Windows, Linux, macOS) и обменивается сообщениями по stdio/stdout (JSON-RPC 2.0).
- [ ] Реализованы базовые методы протокола: `initialize`, `tools/list`, `tools/call`.
- [ ] Доступны инструменты Telegram сервера: `tg_send_message`, `tg_send_photo`, `tg_get_updates` (+ составной `create_issue_and_notify` при наличии GitHub токена).
- [ ] Грейсфул-шатдаун: корректное завершение дочернего процесса, таймаут и убийство при зависании.
- [ ] Ретраи и watchdog при падении сервера (с ограничением на количество рестартов).
- [ ] Конфигурация путей, токенов и таймаутов через `config/*.json` и/или `.env`, без хардкода.
- [ ] Логирование запросов/ответов (корреляция по `traceId`), маскирование секретов.
- [ ] Тесты: юнит (клиент, парсинг, ретраи), интеграционные (фейковый/mock сервер), e2e «сухой прогон».
- [ ] Документация: README обновлён, описан запуск, конфиги и отладка.

## Архитектура
- Клиент MCP (Python) в `telegram_monitoring_agent/src/mcp/`:
  - Транспорт stdio: запуск `node mcp_servers/telegram_mcp_server/server.js` как subprocess с привязкой stdin/stdout.
  - JSON-RPC оболочка: очередь запросов, соответствие `id -> future`, таймауты, обработка ошибок.
  - Протокол MCP: `initialize` (capabilities), `tools/list` (кэширование на сессию), `tools/call` (унифицированный вызов).
  - Управление жизненным циклом: старт/рестарт, healthcheck/handshake, shutdown.
  - Обогащение логов: `traceId`, durationMs, метрики (счётчики/гистограммы в dev-режиме).
- Интеграция в агента мониторинга:
  - Сервис-обёртка `TelegramMcpService` с методами `send_message`, `send_photo`, `get_updates`.
  - Использование сервиса в существующих пайплайнах/хэндлерах уведомлений.

## Этапы работ

### Этап 0 — Подготовка
- [ ] Проверить наличие Node.js в окружении разработчика и CI.
- [ ] Убедиться, что `mcp_servers/telegram_mcp_server/` консистентен и запускается локально (см. README в папке сервера).
- [ ] Спецификация протокола: актуализировать ссылки в `docs/mcp/stdio_link_protocols.md` и подтверждённые методы.

### Этап 1 — Клиент MCP (stdio) и запуск процесса
- [ ] Создать пакет `src/mcp/` и классы: `McpProcess`, `McpStdIoTransport`, `McpJsonRpcClient`.
- [ ] Реализовать запуск процесса: команда, рабочая директория, переменные окружения.
- [ ] Поддержать буферизацию/фрейминг сообщений по строкам (один JSON на строку) или по `Content-Length` (если требуется) — авто-детект по приветствию/протоколу сервера.
- [ ] Добавить таймауты старта и инициализации; исключения с понятными сообщениями.

### Этап 2 — Протокол MCP и capabilities
- [ ] Реализовать `initialize` и проверку ожидаемых capabilities.
- [ ] Реализовать `tools/list` с кэшированием на сессию (инвалидация по рестарту).
- [ ] Реализовать `tools/call` с унифицированной моделью ответа/ошибки; маппинг кодов ошибок.

### Этап 3 — Сервис Telegram и интеграция в пайплайны
- [ ] Создать `TelegramMcpService` в `src/services/telegram_mcp_service.py`.
- [ ] Методы: `send_message(chat_id, text, ...opts)`, `send_photo(chat_id, file|url, ...opts)`, `get_updates(offset, limit, ...opts)`.
- [ ] Интегрировать в ключевые сценарии агента: отправка уведомлений, репортов, алёртов.
- [ ] Сохранить обратную совместимость (feature flag или авто‑выбор транспорта).

### Этап 4 — Конфигурация и безопасность
- [ ] Добавить секцию в `config/*.json` или `.env` для путей, флагов и токенов:
  - Путь к серверу: `mcp_servers/telegram_mcp_server/server.js`.
  - Флаги: `MCP_ENABLED`, `MCP_TRANSPORT=stdio`, таймауты, retry policy, max restarts.
  - Секреты: `TELEGRAM_BOT_TOKEN`, `TELEGRAM_DEFAULT_CHAT_ID` — не логировать, валидировать при старте.
- [ ] Валидация конфигов + понятные ошибки при отсутствии зависимостей.

### Этап 5 — Надёжность, логи и метрики
- [ ] Ретраи с экспоненциальной паузой на запрос.
- [ ] Watchdog рестарта процесса (с backoff и предельным числом попыток).
- [ ] Корреляционные логи: `traceId`, `rpcMethod`, `durationMs`, статус и размер полезной нагрузки.
- [ ] Метрики (dev): количества вызовов/ошибок, средняя латентность.

### Этап 6 — Тестирование
- [ ] Юнит‑тесты клиента: парсинг, таймауты, ретраи, падения процесса.
- [ ] Интеграционные тесты с mock/fake сервером (эмуляция stdio, -32601 и пр.).
- [ ] E2E dry‑run: локальный запуск реального сервера с «песочными» переменными окружения (без публикации в реальные чаты).
- [ ] Документация по запуску тестов и ограничениям (Windows CI и т. п.).

### Этап 7 — Документация и DX
- [ ] Обновить `telegram_monitoring_agent/README.md`: как включить MCP, конфиги, проверка подключения, часто встречающиеся ошибки.
- [ ] Добавить `docs/mcp_integration.md` с деталями протокола и примерами запрос/ответ.
- [ ] Примеры скриптов/команд для локального запуска и отладки.

### Этап 8 — Релиз и откат
- [ ] Фича‑флаг включения MCP по умолчанию: сначала выключен.
- [ ] Канареечный прогон в тестовой среде.
- [ ] План отката: быстрое отключение MCP без перезапуска сервиса.

## Риски и смягчение
- Процесс/протокол несовместим: предусмотреть fallback режим без MCP, строгую валидацию версий capabilities.
- Утечка секретов в логах: централизованное маскирование значений и ревизия уровней логирования.
- Флаки на Windows при stdio: добавить дополнительные буферы и пайп‑тесты, увеличить таймауты старта.
- Ошибки JSON‑RPC: единый слой маппинга и коды ошибок в документации.

## Планы по времени (оценка)
- Этапы 0–2: 1–2 дня.
- Этапы 3–5: 2–3 дня.
- Этап 6: 1–2 дня.
- Этапы 7–8: 0.5–1 день.

Итого: 4.5–8 дней, зависит от объёма интеграции в существующие пайплайны и стабилизации тестов.
